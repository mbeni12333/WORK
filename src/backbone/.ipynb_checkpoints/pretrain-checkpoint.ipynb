{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d27983e-2ee3-468b-b18f-81880d6c4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall lightning-bolts -y\n",
    "# !pip install git+https://github.com/PytorchLightning/lightning-bolts.git@master --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f8cd9cb-aaf5-400d-8825-93a01d57650a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from PIL import Image\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93bacd4-8afc-43ef-b747-69340424d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import early_stopping, model_checkpoint, ProgressBar, LearningRateMonitor\n",
    "from pl_bolts.models.self_supervised import Moco_v2, BYOL\n",
    "from pl_bolts.transforms.dataset_normalizations import imagenet_normalization\n",
    "from pl_bolts.datamodules import AsynchronousLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6858bada-7f85-4974-8f83-d6a5699605c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48d36a78-35e7-4d8b-aa88-fd603ae531ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path=\"processed_data/\"\n",
    "\n",
    "# dfs= []\n",
    "\n",
    "# for filepath in glob.glob(dataset_path+\"/*/*.json\"):\n",
    "#     with open(filepath, \"r\") as file:\n",
    "        \n",
    "#         data = json.load(file)\n",
    "#         df = pd.DataFrame(data[\"result\"])\n",
    "#         slide = os.path.basename(data[\"slide\"]).split(\".\")[0]\n",
    "#         df[\"local_class\"] = df[\"class\"] == \"tumor\"\n",
    "#         df[\"global_class\"] = slide.split(\"_\")[0] == \"tumor\"\n",
    "#         df[\"path\"] = os.path.join(os.path.dirname(filepath), \"patches\") + \"/\" + df[\"class\"] + \"/\" + df[\"x\"].astype(str).str.zfill(6)+\"_\"+df[\"y\"].astype(str).str.zfill(6)+\".png\"\n",
    "#         df = df.drop(columns=[\"w\", \"h\", \"class\"])\n",
    "#         dfs.append(df)\n",
    "\n",
    "# dataset = pd.concat(dfs)\n",
    "\n",
    "# dataset_path=\"processed_data/\"\n",
    "# dataset.set_index([\"path\"])\n",
    "# dataset.to_csv(dataset_path+\"data.csv\")\n",
    "\n",
    "# dataset[\"path\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68c84a48-2c31-4be8-aef1-2b1a4c506c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "class Camelyon16PreprocessedDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset of unlabelled patches\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, transforms=None):\n",
    "        self.data = data\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patch = self.data.iloc[idx]\n",
    "        img = read_image(patch[\"path\"], mode=ImageReadMode.RGB)/255\n",
    "        label = patch[\"local_class\"]\n",
    "        \n",
    "#         if self.transforms is not None:\n",
    "#             img_t = img\n",
    "#             img2_t = img\n",
    "#         else:\n",
    "#             img_t = img\n",
    "#             img2_t = img\n",
    "        \n",
    "        return (img, img), label\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deb9606e-7b4b-408f-8532-ef85c0cd5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = Camelyon16PreprocessedDataset(\"./processed_data/data.csv\",\n",
    "#                                        transforms=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# dataloader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "#                                          batch_size=1024,\n",
    "#                                          shuffle=True,\n",
    "#                                          prefetch_factor=3,\n",
    "#                                          num_workers=8)\n",
    "\n",
    "# for imgs, labels in dataloader:\n",
    "\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.title((1.0*labels).mean(), fontsize=18)\n",
    "#     plt.imshow(make_grid(imgs, 32).numpy().transpose(1, 2, 0))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d048fa6-92ce-4585-8cbc-115a6a7712ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "moco_transform = nn.Sequential(transforms.ColorJitter(0.8, 0.8, 0.8, 0.2),\n",
    "                                   transforms.GaussianBlur(23, sigma=(0.1, 2.0)),\n",
    "                                   transforms.RandomHorizontalFlip(),\n",
    "                                   transforms.RandomVerticalFlip(),\n",
    "                                   transforms.RandomResizedCrop(224),\n",
    "                                   transforms.RandomGrayscale(),\n",
    "                                   imagenet_normalization()).to(device).eval()\n",
    "moco_transform_scripted = torch.jit.script(moco_transform).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fec7c16-d3d1-4ddc-ae1c-c64442be23df",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "class Camelyon16Preprocessed(pl.LightningDataModule):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path=\"processed_data\", valid_portion=0.2, warmup=1):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.data = pd.read_csv(os.path.join(self.data_path, \"data.csv\"))\n",
    "        idx = np.arange(len(self.data))\n",
    "        np.random.shuffle(idx)\n",
    "        idx = idx[:int(len(idx)*warmup)]\n",
    "        self.train_idx = idx[int(len(idx)*valid_portion):]\n",
    "        self.valid_idx = idx[:int(len(idx)*valid_portion)]\n",
    "        \n",
    "\n",
    "    def vale_dataloader(self):\n",
    "    \n",
    "        dataset = Camelyon16PreprocessedDataset(self.data.iloc[self.valid_idx],\n",
    "                                       transforms=[transforms.ToTensor(),transforms.ToTensor()])\n",
    "            \n",
    "        dataloader = AsynchronousLoader(torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                         batch_size=128,\n",
    "                                         prefetch_factor=4,\n",
    "                                         num_workers=8,\n",
    "                                         pin_memory=True,\n",
    "                                         drop_last=True), device=device)\n",
    "        \n",
    "        return dataloader\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        dataset = Camelyon16PreprocessedDataset(self.data.iloc[self.train_idx],\n",
    "                                       transforms=[transforms.ToTensor(),transforms.ToTensor()])\n",
    "                                        \n",
    "        \n",
    "        dataloader = AsynchronousLoader(torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                         batch_size=256,\n",
    "                                         shuffle=True,\n",
    "                                         prefetch_factor=8,\n",
    "                                         num_workers=8,\n",
    "                                         pin_memory=True,\n",
    "                                         drop_last=True), device=device)\n",
    "        return dataloader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a62f774-5080-4a33-a093-6f275b75bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mocov2_gpu_transform(Moco_v2):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        zero_img = torch.FloatTensor(np.zeros((1, 3, 224, 224)))\n",
    "        zero_queue = torch.FloatTensor(np.zeros((128, 8192)))\n",
    "        self.example_input_array = (zero_img, zero_img, zero_queue)\n",
    "    \n",
    "#     def forward(self, img_q, img_k, queue):\n",
    "#         breakpoint() \n",
    "#         return super().forward(img_q, img_k, queue)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        (img_q, img_k), label = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            img_q = moco_transform(img_q)\n",
    "            img_k = moco_transform(img_k)\n",
    "\n",
    "        batch = (img_q, img_k), label\n",
    "\n",
    "        return super().training_step(batch, batch_idx)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        (img_q, img_k), label = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            img_q = moco_transform(img_q)\n",
    "            img_k = moco_transform(img_k)\n",
    "\n",
    "        batch = (img_q, img_k), label\n",
    "        \n",
    "        return super().validation_step(batch, batch_idx)\n",
    "\n",
    "    \n",
    "class Byol_gpu_transform(BYOL):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        zero_img = torch.FloatTensor(np.zeros((1, 3, 224, 224)))\n",
    "        self.example_input_array = zero_img\n",
    "    \n",
    "#     def forward(self, img_q, img_k, queue):\n",
    "#         breakpoint() \n",
    "#         return super().forward(img_q, img_k, queue)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        (img_q, img_k), label = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            img_q = moco_transform(img_q)\n",
    "            img_k = moco_transform(img_k)\n",
    "\n",
    "        batch = (img_q, img_k), label\n",
    "\n",
    "        return super().training_step(batch, batch_idx)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        (img_q, img_k), label = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            img_q = moco_transform(img_q)\n",
    "            img_k = moco_transform(img_k)\n",
    "\n",
    "        batch = (img_q, img_k), label\n",
    "        \n",
    "        return super().validation_step(batch, batch_idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ec1fd7e-8cf8-4672-a596-b6aae498a833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using native 16bit precision.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = model_checkpoint.ModelCheckpoint(dirpath='models/encoder',\n",
    "                                                       monitor=\"train_loss\")\n",
    "\n",
    "earlystop_callback = early_stopping.EarlyStopping(monitor=\"train_loss\")\n",
    "\n",
    "lrmonitor_callback = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "\n",
    "datamodule = Camelyon16Preprocessed()\n",
    "\n",
    "\n",
    "model = Mocov2_gpu_transform(\"resnet50\",\n",
    "                embd_dim=2048,\n",
    "                #num_negatives=8192,\n",
    "                use_mlp=True,\n",
    "                batch_size=256,\n",
    "                learning_rate=0.03)\n",
    "\n",
    "# model = Byol_gpu_transform(num_classes=1,\n",
    "#              input_height=224,\n",
    "#              batch_size=128,\n",
    "#              warmup_epochs=1,\n",
    "#              max_epochs=20,\n",
    "#              num_workers=8,\n",
    "#              base_encoder=\"resnet50\")\n",
    "\n",
    "logger = TensorBoardLogger(\"lightning_logs\", default_hp_metric=False, name=\"MOCO\", log_graph=True)\n",
    "\n",
    "trainer = pl.trainer.Trainer(gpus=1, callbacks=[checkpoint_callback],\n",
    "                             max_epochs=10,resume_from_checkpoint=\"models/encoder/moco.ckpt\",\n",
    "                             precision=16,accumulate_grad_batches=8,\n",
    "                             logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "635ec6d8-2b24-4632-80fe-be4e7dbf3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test Debug if everything works\n",
    "# debug_trainer = pl.trainer.Trainer(gpus=1,fast_dev_run=True,callbacks=[checkpoint_callback],\n",
    "#                                  profiler=\"pytorch\",\n",
    "#                                  max_epochs=10,\n",
    "#                                  precision=16)\n",
    "# debug_trainer.fit(model,datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff5751-1aa0-4c83-88a8-c6fecab773f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint file at models/encoder/moco.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Restored all states from the checkpoint file at models/encoder/moco.ckpt\n",
      "\n",
      "  | Name      | Type   | Params | In sizes         | Out sizes\n",
      "--------------------------------------------------------------------\n",
      "0 | encoder_q | ResNet | 28.0 M | [1, 3, 224, 224] | [1, 128] \n",
      "1 | encoder_k | ResNet | 28.0 M | [1, 3, 224, 224] | [1, 128] \n",
      "--------------------------------------------------------------------\n",
      "28.0 M    Trainable params\n",
      "28.0 M    Non-trainable params\n",
      "55.9 M    Total params\n",
      "223.733   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8963e21f74a8438c8584937fa9a70e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model,datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2284d8-c64f-4052-af55-519d09190248",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb8ef5-ae76-4e89-84b0-1b0e6330ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = nn.Sequential(*list(model.encoder_q.children())[:-1]).cpu().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b86bb-db2f-44ac-9631-ced60e13e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(feature.state_dict(), \"models/encoder/mocov3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb5d6e-2f04-4a30-b531-c70fa8e44214",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cffb79-e897-4737-86cb-678876294473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
